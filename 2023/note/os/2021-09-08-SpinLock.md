---
title: "zooKeeper"
date: 2021-08-20
description: "源码剖析"
draft: false
tags: ["源码剖析"]
---





我使用的技巧

内核代码 ：

https://elixir.bootlin.com/linux/latest/source/include/linux/spinlock.h#L357

内核文档：

https://www.kernel.org/doc/Documentation/locking/spinlocks.txt

https://www.kernel.org/doc/Documentation/



讨论群：https://groups.google.com/g/zh-kernel/













## 问：什么情况下需要线程同步，使用场景是什么



### 互斥锁

### 概念上理解？如何唤醒，如何加锁 ，租塞的

- 只有一个资源 

- 可能长期占用锁 【长期占用锁】

- 成对出现 ，加锁和解锁 必须在一个函数里面。

- 互斥锁同一时间只允许一个线程访问该对象，无论读写

- 内核态和用户态的混合机制。

  1、互斥锁的结构？

  在futex的基础上用的内存共享变量来实现的。

  2、不能锁住的时候，是如何进入休眠，又如何等待被唤醒的呢？

  进入锁的时候就会区检查那个共享变量，如果不能获取锁，就会通过futex系统调用进入休眠。如果有人释放锁，就会通过futex来唤醒

  Enable futex suppor

  

  1. 什么是Futex
     Futex 是Fast Userspace muTexes的缩写，由Hubertus Franke, Matthew Kirkwood, Ingo Molnar and Rusty Russell共同设计完成。几位都是linux领域的专家，其中可能Ingo Molnar大家更熟悉一些，毕竟是O(1)调度器和CFS的实现者。

  

  2.

  

  \4. 进/线程利用futex同步
  进程或者线程都可以利用futex来进行同步。
  对于线程，情况比较简单，因为线程共享虚拟内存空间，虚拟地址就可以唯一的标识出futex变量，即线程用同样的虚拟地址来访问futex变量。
  对 于进程，情况相对复杂，因为进程有独立的虚拟内存空间，只有通过mmap()让它们共享一段地址空间来使用futex变量。每个进程用来访问futex的 虚拟地址可以是不一样的，只要系统知道所有的这些虚拟地址都映射到同一个物理内存地址，并用物理内存地址来唯一标识futex变量。 

  小结：
  \1. Futex变量的特征：1)位于共享的用户空间中 2)是一个32位的整型 3)对它的操作是原子的
  \2. Futex在程序low-contention的时候能获得比传统同步机制更好的性能。
  \3. 不要直接使用Futex系统调用。
  \4. Futex同步机制可以用于进程间同步，也可以用于线程间同步。

  

  - 那mutex和semaphore有什么区别呢？mutex是用作互斥的，而semaphore是用作同步的。也就是说，mutex的初始化一定是为1，而semaphore可以是任意的数

  

  ### 二、实现

  1.  Glibc中的所提供的线程同步方式：利用futex机制和linux配合完成同步操作就可以
  
  - 青铜：你知道，别人也知道
  
    ~~~
    Mutex
    变量定义：    pthread_mutex_t mut;
    初始化：      pthread_mutex_init(&mut,NULL);
    进入加锁:     pthread_mutex_lock(&mut);
    退出解锁:     pthread_mutex_unlock(&mut);
    
    
    ~~~
  
  - 白银：你不知道，别人知道
  
  ~~~c
  
  https://code.woboq.org/userspace/glibc/nptl/sem_wait.c.html
  int __new_sem_wait (sem_t *sem)
  {
    /* We need to check whether we need to act upon a cancellation request here
       because POSIX specifies that cancellation points "shall occur" in
       sem_wait and sem_timedwait, which also means that they need to check
       this regardless whether they block or not (unlike "may occur"
       functions).  See the POSIX Rationale for this requirement: Section
       "Thread Cancellation Overview" [1] and austin group issue #1076 [2]
       for thoughs on why this may be a suboptimal design.
       [1] http://pubs.opengroup.org/onlinepubs/9699919799/xrat/V4_xsh_chap02.html
       [2] http://austingroupbugs.net/view.php?id=1076 for thoughts on why this
     */
    __pthread_testcancel ();
    if (__new_sem_wait_fast ((struct new_sem *) sem, 0) == 0)
      return 0;
    else
      return __new_sem_wait_slow((struct new_sem *) sem, NULL);
  }
  
  https://code.woboq.org/userspace/glibc/nptl/sem_waitcommon.c.html#__new_sem_wait_fast
  https://code.woboq.org/userspace/glibc/nptl/sem_waitcommon.c.html#__new_sem_wait_slow
  https://code.woboq.org/userspace/glibc/sysdeps/pthread/semaphore.h.html
  
  
  
  #include <linux/futex.h>
    #include <sys/time.h>
    int futex (int *uaddr, int op, int val, const struct timespec *timeout,int *uaddr2, int val3);
    #define __NR_futex       240
  
  
  
  ~~~
  
  >  golang sync.Mutex互斥锁的实现原理



~~~
https://blog.csdn.net/yizhiniu_xuyw/article/details/113862446

~~~

### golang 实现

- 类定义：很清楚 直接说明本质  需要信号量和value

type Mutex struct {
	state int32
	sema  uint32   //信号量，向处于Gwaitting的G发送信号
}



Mutex的状态机比较复杂，使用一个int32来表示：【没看懂】

```go
const (
	mutexLocked = 1 << iota // mutex is locked
	mutexWoken  //2
	mutexStarving //4
	mutexWaiterShift = iota //3
)
       
mutexLocked — 表示互斥锁的锁定状态；
mutexWoken — 表示从正常模式被从唤醒；
mutexStarving — 当前的互斥锁进入饥饿状态；
waitersCount — 当前互斥锁上等待的 goroutine 个数；

32                                               3             2             1             0 
 |                                               |             |             |             | 
 |                                               |             |             |             | 
 v-----------------------------------------------v-------------v-------------v-------------+ 
 |                                               |             |             |             v 
 |                 waitersCount                  |mutexStarving| mutexWoken  | mutexLocked | 
 |                                               |             |             |             | 
 +-----------------------------------------------+-------------+-------------+-------------+  
————————————————
版权声明：本文为CSDN博主「一只牛_007」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/yizhiniu_xuyw/article/details/113862446
```



- 加锁函数
- 解锁函数

~~~go
// Unlock unlocks m.
// It is a run-time error if m is not locked on entry to Unlock.
//
// A locked Mutex is not associated with a particular goroutine.
// It is allowed for one goroutine to lock a Mutex and then
// arrange for another goroutine to unlock it.
func (m *Mutex) Unlock() {

  // Fast path: drop lock bit.
	new := atomic.AddInt32(&m.state, -mutexLocked) //就自己一个人使用
	if new != 0 {
		
		// Outlined slow path to allow inlining the fast path.
		// To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock.
		//如果该函数返回的新状态不等于 0，这段代码会调用 sync.Mutex.unlockSlow 方法开始慢速解锁
		m.unlockSlow(new)
	} //如果该函数返回的新状态等于 0，当前 Goroutine 就成功解锁了互斥锁；
}

func (m *Mutex) unlockSlow(new int32) {
	if (new+mutexLocked)&mutexLocked == 0 {
		throw("sync: unlock of unlocked mutex")
	}
  
	if new&mutexStarving == 0 {
		old := new
		for {
			// If there are no waiters or a goroutine has already
			// been woken or grabbed the lock, no need to wake anyone.
			// In starvation mode ownership is directly handed off from unlocking
			// goroutine to the next waiter. We are not part of this chain,
			// since we did not observe mutexStarving when we unlocked the mutex above.
			// So get off the way.
			if old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 {
				return
			}
			// Grab the right to wake someone.
			new = (old - 1<<mutexWaiterShift) | mutexWoken
			if atomic.CompareAndSwapInt32(&m.state, old, new) {
				runtime_Semrelease(&m.sema, false, 1)
				return
			}
			old = m.state
		}
	} else {
		// Starving mode: handoff mutex ownership to the next waiter, and yield
		// our time slice so that the next waiter can start to run immediately.
		// Note: mutexLocked is not set, the waiter will set it after wakeup.
		// But mutex is still considered locked if mutexStarving is set,
		// so new coming goroutines won't acquire it.
		runtime_Semrelease(&m.sema, true, 1)
	}
}
~~~



### 条件变量

https://zh.wikipedia.org/wiki/%E8%87%AA%E6%97%8B%E9%94%81



### 一、概念上理解

### 二、实现





1. daily_read_coding/go-go1.17/src/sync/cond.go

~~~go

// Cond implements a condition variable, a rendezvous point
// for goroutines waiting for or announcing the occurrence
// of an event.
//
// Each Cond has an associated Locker L (often a *Mutex or *RWMutex),
// which must be held when changing the condition and
// when calling the Wait method.
//
// A Cond must not be copied after first use.
type Cond struct {
	// L is held while observing or changing the condition
	L Locker //可以传入一个读写锁或互斥锁，当修改条件或者调用wait方法时需要加锁
	notify  notifyList //	notify  notifyList 
}

// Approximation of notifyList in runtime/sema.go. Size and alignment must
// agree.
type notifyList struct {
	wait   uint32 //下一个等待唤醒Goroutine的索引，他是在锁外自动递增的
	notify uint32 //下一个要通知的Goroutine的索引，他可以在锁外读取，但是只能在锁持有的情况下写入.
	lock   uintptr // key field of the mutex
	head   unsafe.Pointer //指向链表的头部
	tail   unsafe.Pointer //指向链表的尾部
}


~~~







函数：唤醒



~~~
// Signal wakes one goroutine waiting on c, if there is any.
//
// It is allowed but not required for the caller to hold c.L
// during the call.
func (c *Cond) Signal() {
	c.checker.check()
	runtime_notifyListNotifyOne(&c.notify)
}

// See runtime/sema.go for documentation.
func runtime_notifyListNotifyOne(l *notifyList)
~~~



### 三、优化





### 自旋锁**spinlock**原理



### [概念上理解](https://zh.wikipedia.org/wiki/%E8%87%AA%E6%97%8B%E9%94%81)



1. **旋锁**是[计算机科学](https://zh.wikipedia.org/wiki/计算机科学)用于多线程[同步](https://zh.wikipedia.org/wiki/同步_(计算机科学))的一种[锁](https://zh.wikipedia.org/wiki/互斥锁)，【有很多种，为什么选择这个】

2. 自旋锁避免了进程上下文的调度开销，因此对于线程只会阻塞很短时间的场合是有效的【[忙等待](https://zh.wikipedia.org/wiki/忙等待)】

3. 单核CPU不适于使用自旋锁，这里的单核CPU指的是单核单线程的CPU，因为，在同一时间只有一个线程是处在运行状态，假设运行线程A发现无法获取锁，只能等待解锁，但因为A自身不挂起，所以那个持有锁的线程B没有办法进入运行状态，只能等到操作系统分给A的时间片用完，才能有机会被调度。这种情况下使用自旋锁的代价很高。

4. 获取、释放自旋锁，实际上是读写自旋锁的存储内存或寄存器。因此这种读写操作必须是[原子的](https://zh.wikipedia.org/wiki/原子操作)。通常用[test-and-set](https://zh.wikipedia.org/wiki/Test-and-set)等原子操作来实现【加锁逻辑是什么，和其他有什么不同 ⚠️】

5. Windows操作系统提供的轻型[读写锁](https://zh.wikipedia.org/wiki/读写锁)（SRW Lock）内部就用了自旋锁

6. **自旋锁最初就是为了SMP系统设计的，实现在多处理器情况下保护临界区**
   自旋锁只有在内核可抢占或SMP（多处理器）的情况下才真正需要，在单CPU且不可抢占的内核下，自旋锁的所有操作都是空操作。

7.   首先spinlock是只有在内核态才有的，当然你也可以在用户态自己实现，但是如果想要调用spinlock_t类型，那只有内核态才有。但是semaphore是内核态和用户态都有的，mutex是一种特殊的semaphore。

   





### 二 代码



#### liunx ：

https://github.com/watchpoints/linux/blob/master/include/linux/spinlock.h

https://kernelnewbies.kernelnewbies.narkive.com/giA3UIK3/spinlock-on-uniprocessor-systems



~~~c
https://blog.csdn.net/yhb1047818384/article/details/84677203
typedef struct {
    unsigned int slock;
} raw_spinlock_t;

//传统的自旋锁本质上用一个整数来表示，值为1代表锁未被占用, 为0或者为负数表示被占用。

在单处理机环境中可以使用特定的原子级汇编指令swap和test_and_set实现进程互斥
  
  
  在多处理机环境中情况有所不同，例如test_and_set指令包括“取”、“送”两个指令周期，两个CPU执行test_and_set(lock)可能发生指令周期上的交叉，假如lock初始为0, CPU1和CPU2可能分别执行完前一个指令周期并通过检测(均为0)，然后分别执行后一个指令周期将lock设置为1，结果都取回0作为判断临界区空闲的依据，从而不能实现互斥.
  
  
为在多CPU环境中利用test_and_set指令实现进程互斥，硬件需要提供进一步的支持，以保证test_and_set指令执行的原子性. 这种支持目前多以“锁总线”(bus locking)的形式提供的，由于test_and_set指令对内存的两次操作都需要经过总线，在执行test_and_set指令之前锁住总线，在执行test_and_set指令后开放总线，即可保证test_and_set指令执行的原子性。
用法如下：
————————————————
版权声明：本文为CSDN博主「Hober_yao」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/yhb1047818384/article/details/84677203


~~~

- 多处理机互斥算法（自旋锁算法）

  >由于test_and_set指令对内存的两次操作都需要经过总线，在执行test_and_set指令之前锁住总线，在执行test_and_set指令后开放总线，即可保证test_and_set指令执行的原子性。

  ~~~
  do{
  	b=1;
  	while(b) {
  		lock(bus);
  		b = test_and_set(&lock);
  		unlock(bus);
  	}
  	临界区
  	lock = 0;
  	其余部分
  }while(1)
  ~~~

  

  

- linux内核中锁的实现

~~~c

/          一般的上锁
static inline void spin_lock(spinlock_t *lock)
{
	raw_spin_lock(&lock->rlock);
}
//           通常用在进程中，用来禁止抢断和禁止软中断
static inline void spin_lock_bh(spinlock_t *lock)
{
	raw_spin_lock_bh(&lock->rlock);
}
//          判断有没有上锁
static inline int spin_trylock(spinlock_t *lock)
{
	return raw_spin_trylock(&lock->rlock);
}
//           既禁止本地中断，又禁止内核抢占
static inline void spin_lock_irq(spinlock_t *lock)
{
	raw_spin_lock_irq(&lock->rlock);
}


static inline void __raw_spin_lock(raw_spinlock_t *lock)
{
	__asm__ __volatile__(
		__raw_spin_lock_string
		:"=m" (lock->slock) : : "memory");
}
https://www.cnblogs.com/ph829/p/4429093.html

#define raw_spin_lock_irq(lock)		_raw_spin_lock_irq(lock) //中断
#define raw_spin_lock_bh(lock)		_raw_spin_lock_bh(lock)
#define raw_spin_unlock(lock)		_raw_spin_unlock(lock)
#define raw_spin_unlock_irq(lock)	_raw_spin_unlock_irq(lock)

https://github.com/freelancer-leon/notes/blob/master/kernel/lock/Lock-2-Linux_x86_Spin_Lock.md


https://elixir.bootlin.com/linux/latest/source/include/linux/spinlock_api_smp.h#L132
static inline void __raw_spin_lock_bh(raw_spinlock_t *lock)
{
	__local_bh_disable_ip(_RET_IP_, SOFTIRQ_LOCK_OFFSET);
	spin_acquire(&lock->dep_map, 0, 0, _RET_IP_);
	LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);
}

static inline void __raw_spin_lock(raw_spinlock_t *lock)
{
	preempt_disable();
	spin_acquire(&lock->dep_map, 0, 0, _RET_IP_);
	LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);
}
~~~





- 疑问：spin_lock为什么要关闭抢占？



~~~
The reason that preemption is disabled on a uniprocessor system is:
在单处理器系统上禁用抢占的原因是：

If not:
P1 holds the lock and after a time is scheduled out.

Now P2 starts executing and let’s say requests the same spinlock. Since P1 has not released the spinlock, P2 must spin and do nothing. So the execution time of P2 is wasted. 

It makes more sense to let P1 release the lock and then allow it to be preempted.

Also since there is no other processor, simply by disallowing preemption we know that there will never be another process that runs in parallel on another processor and accesses the same critical section


https://kernelnewbies.kernelnewbies.narkive.com/giA3UIK3/spinlock-on-uniprocessor-systems

LDD 3rd ed page 115 says

" Spinlocks are, by their nature, intended for use on multiprocessor
systems,although a uniprocessor workstation running a preemptive kernel
behaves like SMP, as far as concurrency is concerned.If a nonpreemptive
uniprocessor system ever went into a spin on a lock, it would spin forever;
no other thread would ever be able to obtain the CPU to release the lock.
For this reason, spinlock operations on uniprocessor systems without
preemption enabled are optimized to do nothing, with the exception of the
ones that change the IRQ masking status. "

I want to ask what does it mean by " if a nonpreemptive uniprocessor system
ever went into a spin on a lock, it would spin forever,no other thread would
ever be able to obtain the CPU to release the lock " .

Why is it so? and how ? can someone plz send me a code snippet to explain
this statement ?

" 自旋锁，就其本质而言，旨在用于多处理器
系统，尽管运行抢占式内核的单处理器工作站
就并发而言，其行为类似于 SMP。如果非抢占式
单处理器系统曾经在锁上旋转，它将永远旋转；
没有其他线程能够获得 CPU 来释放锁。
出于这个原因，单处理器系统上的自旋锁操作没有
启用抢占被优化为什么都不做，除了
改变 IRQ 屏蔽状态的那些。 ”

我想问一下“如果一个非抢占式单处理器系统”是什么意思
曾经在锁上旋转，它会永远旋转，没有其他线程会
曾经能够获得CPU释放锁”。

为什么会这样？ 如何 ？ 有人可以给我发一个代码片段来解释吗
这个说法 ？


~~~





- 疑问：不被抢占 类似xie成，【10000，10 20 】

~~~
Spinlock is a busy-wait lock means that a task will spin at the
spinlock (keep processor busy) until it won't able to acquire it. So
on SMP machine one processor can spin on spinlock and the other one
can release the lock after doing stuff with-in lock and unlock ! Now
if the system is uniprocessor and no preemption is enabled tries to
acquire the lock (which is already acquired by some other process, but
the process must schedule itself after acquiring lock to make this
happen as uniprocessor system without preemption won't allow other
process to execute at the same time) then it will spin on the lock and
won't allow the CPU to give time to the other process which is
supposed to release the lock

自旋锁是忙等待锁意味着任务将在
自旋锁（保持处理器忙碌）直到它无法获取它。 所以
在 SMP 机器上，一个处理器可以在自旋锁上旋转，另一个处理器可以旋转
可以在做带锁和解锁的事情后释放锁！ 现在
如果系统是单处理器且未启用抢占，则尝试
获取锁（已经被其他进程获取，但是
进程必须在获取锁后自行调度以实现此目的
因为没有抢占的单处理器系统不允许其他
进程同时执行）然后它会在锁上旋转并
不允许 CPU 为其他进程提供时间
应该释放锁
https://www.kernel.org/doc/htmldocs/kernel-locking/uniprocessor.html

https://kernelnewbies.kernelnewbies.narkive.com/giA3UIK3/spinlock-on-uniprocessor-systems


~~~



3.  继续看

问：请教一下，获取spinlock时，为什么要将调用preempt_disable?

https://groups.google.com/g/zh-kernel/c/ReAvGJphj5s?pli=1



答：继续看

https://kernelnewbies.kernelnewbies.narkive.com/giA3UIK3/spinlock-on-uniprocessor-systems
Gaurav Dhiman 回答
http://www.wowotech.net/kernel_synchronization/spinlock.html





```





yes, when we acquire the spinlock, preemption is disabled.
是的，当我们获得自旋锁时，抢占被禁用。

yes, we can not afford to sleep (which eventually reschedules other
process on this CPU) or make a call to schedule() function or do
something which eventually calls schedule() function, while we are
holding a spinlock.

是的，我们睡不起（这最终会重新安排其他
在此 CPU 上处理）或调用 schedule() 函数或执行
最终调用 schedule() 函数的东西，而我们
持有自旋锁。

画外音：

条件：已经持有自旋锁
任务：不能sleep 因为schedule到其他函数去了


为了理解问题查阅资料：

proc 实际上是 Linux 的一个虚拟文件系统，用于内核空间与用户空间之间的通信。
/proc/interrupts 就是这种通信机制的一部分，提供了一个只读的中断使用情况。
watch -d cat /proc/interrupts

Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间
进程既可以在用户空间运行，又可以在内核空间中运行。

进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。
小·小··
从用户态到内核态的转变，需要通过系统调用来完成

一次系统调用的过程，其实是发生了两次 CPU 上下文切换。


对同一个 CPU 来说，中断处理比进程拥有更高的优先级，
所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，
由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。
为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行

用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。


对于32位的机器来说，虚拟的地址空间大小就是4G

https://www.cnblogs.com/youxin/p/3313288.html
https://www.cnblogs.com/youxin/p/3313288.html
https://www.cnblogs.com/youxin/p/3313288.html
https://gaomf.cn/2017/09/28/Detect_Stack_Direction/
用代码判断栈的增长方向

	
```



### 三、优化



危害：***[防止关闭了抢占的临界区被同一个CPU的高优先级序列打断而重入时造成死锁](https://blog.csdn.net/dog250/article/details/108784871?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-2.no_search_link)***

1. 由于C1被C2抢占，而C2已经自旋，因此妥妥死锁！







##  为了理解这个问题，我查看的资料

- https://www.zhihu.com/question/66733477 【开始--青铜】
- 自旋锁的原理与优化 #63 https://github.com/kunpengcompute/kunpengcompute.github.io/issues/63 【开始--王者】

1. https://www.postgresql.org/message-id/flat/CAB10pyamDkTFWU_BVGeEVmkc8%3DEhgCjr6QBk02SCdJtKpHkdFw%40mail.gmail.com



- [源码剖析sync.cond(条件变量的实现机制）](https://juejin.cn/post/6931292970125623303) 【开始--】
- [golang sync.Mutex互斥锁的实现原理](https://blog.csdn.net/yizhiniu_xuyw/article/details/113862446) 【开始--】
- [pthread_mutex_lock实现](https://www.cnblogs.com/pslydff/p/7041444.html) 【开始- 看不懂 -后面在看 --5分】
- Linux Futex的设计与实现 【开始- 看不懂 -后面在看 --8分】
- [linux内核--自旋锁的理解](https://www.cnblogs.com/alantu2018/p/9176180.html) 【王者 开始---】
- https://github.com/freelancer-leon/notes/blob/master/kernel/lock/Lock-2-Linux_x86_Spin_Lock.md
